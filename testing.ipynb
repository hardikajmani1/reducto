{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from reducto.data_loader import dump_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_root = '/home/lucifer/Documents/Uchicago/winter 22/practicum/dataset'\n",
    "dataset_root = '/Users/hardikajmani/Documents/uchicago/winter 22/Practicum/dataset'\n",
    "names        = ['auburn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = {\n",
    "    name: {\n",
    "        subset.name: [\n",
    "            segment.name\n",
    "            for segment\n",
    "            in sorted((Path(dataset_root) / name / subset).iterdir())\n",
    "            if segment.match('segment???.mp4')]\n",
    "        for subset in [\n",
    "            s\n",
    "            for s\n",
    "            in sorted((Path(dataset_root) / name).iterdir())\n",
    "            if s.is_dir()\n",
    "        ]\n",
    "    }\n",
    "    for name in names\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auburn': {'raw000': ['segment001.mp4']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_json(video_list, 'video_list.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vidoer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from reducto.differencer import PixelDiff, AreaDiff, CornerDiff, EdgeDiff\n",
    "from reducto.videoer import Videoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/hardikajmani/Documents/uchicago/winter 22/Practicum/dataset/auburn/raw000/segment001.mp4')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_root = '/home/lucifer/Documents/Uchicago/winter 22/practicum/dataset'\n",
    "dataset_name = 'auburn'\n",
    "subset_pattern = 'raw000'\n",
    "segment_root = Path(dataset_root) / dataset_name / subset_pattern\n",
    "segments = [f for f in sorted(segment_root.iterdir()) if f.match('segment???.mp4')]\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting transmitting...\n"
     ]
    }
   ],
   "source": [
    "videoer = Videoer(dataset_root=dataset_root,\n",
    "                      dataset_name=dataset_name,\n",
    "                      subset_pattern=subset_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = [\n",
    "        PixelDiff(thresh=0.01),\n",
    "        AreaDiff(thresh=0.01),\n",
    "        CornerDiff(thresh=0.01),\n",
    "        EdgeDiff(thresh=0.01)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "segment001,diff_vector,pixel,1645167932.462325,1645167933.957053,1.4947278499603271\n",
      "segment001,diff,pixel,1645167933.958884,1645167933.958994,0.00010991096496582031\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for dp in dps:\n",
    "        sent = videoer.send_next(dp)\n",
    "        while sent is True:\n",
    "            sent = videoer.send_next(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "\n",
    "import mongoengine\n",
    "import yaml\n",
    "\n",
    "from reducto.data_loader import dump_json\n",
    "from reducto.differencer import DiffComposer\n",
    "from reducto.evaluator import MetricComposer\n",
    "from reducto.inferencer import Yolo\n",
    "from reducto.model import Segment, Inference, InferenceResult, DiffVector, FrameEvaluation\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'environs': {'dataset_root': '/home/lucifer/Documents/Uchicago/winter 22/practicum/dataset',\n",
       "  'thresh_root': 'config/threshes',\n",
       "  'dataset_name': 'auburn',\n",
       "  'subsets': ['raw000']},\n",
       " 'mongo': {'host': 'localhost', 'port': 27017},\n",
       " 'inference': {'type': 'yolo'},\n",
       " 'differencer': {'use_dict': True, 'types': ['pixel']},\n",
       " 'motioner': {'type': 'adapative_bg_learning'},\n",
       " 'evaluator': [{'type': 'coco', 'class': [0]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = 'pipelines/pipeline-auburn-testing.yaml'\n",
    "with open(configuration, 'r') as y:\n",
    "    config = yaml.load(y, Loader=yaml.FullLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/hardikajmani/Documents/uchicago/winter 22/Practicum/dataset/auburn/raw000/segment001.mp4')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets = ['raw000']\n",
    "segments = []\n",
    "segment_pattern = 'segment???.mp4'\n",
    "for ss in subsets:\n",
    "    p = Path(dataset_root) / dataset_name / ss\n",
    "    segments += [f for f in sorted(p.iterdir()) if f.match(segment_pattern)]\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to localhost:27017 on dataset auburn\n"
     ]
    }
   ],
   "source": [
    "mongo_host = config['mongo']['host']\n",
    "mongo_port = config['mongo']['port']\n",
    "mongoengine.connect(dataset_name, host=mongo_host, port=mongo_port)\n",
    "print(f'connected to {mongo_host}:{mongo_port} on dataset {dataset_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "differ_dict_path = Path(config['environs']['thresh_root']) / f'{dataset_name}.json'\n",
    "differ_types = config['differencer']['types']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardikajmani/Library/Python/3.8/lib/python/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "Restoring parameters from weights/yolov3/yolov3.ckpt\n"
     ]
    }
   ],
   "source": [
    "# component preparation\n",
    "no_session = False\n",
    "model = Yolo(no_session=no_session)\n",
    "differ = DiffComposer.from_jsonfile(differ_dict_path, differ_types)\n",
    "evaluator = MetricComposer.from_json(config['evaluator'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_diffeval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"
     ]
    }
   ],
   "source": [
    "# pipeline running\n",
    "pbar = tqdm(total=len(segments))\n",
    "for segment in segments:\n",
    "\n",
    "    # -- segment ---------------------------------------------------\n",
    "    segment_record = Segment.find_or_save(segment.parent.name, segment.name)\n",
    "\n",
    "    # -- inference -------------------------------------------------\n",
    "    inference_record = Inference.objects(\n",
    "        segment=segment_record,\n",
    "        model=model.name,\n",
    "    ).first()\n",
    "    if inference_record:\n",
    "        inference = inference_record.to_json()\n",
    "    else:\n",
    "        inference = model.infer_video(segment)\n",
    "        inference_record = Inference(\n",
    "            segment=segment_record,\n",
    "            model=model.name,\n",
    "            result=[InferenceResult.from_json(inf) for _, inf in inference.items()],\n",
    "        )\n",
    "        inference_record.save()\n",
    "    dump_json(inference, f'data/inference/{dataset_name}/{segment.parent.name}/{segment.stem}.json', mkdir=True)\n",
    "\n",
    "    # -- skip if required ------------------------------------------\n",
    "    if skip_diffeval:\n",
    "        pbar.update()\n",
    "        continue\n",
    "\n",
    "    # -- diff ------------------------------------------------------\n",
    "    diff_vectors = {\n",
    "        dv_record.differencer: dv_record.vector\n",
    "        for dv_record in DiffVector.objects(segment=segment_record)\n",
    "    }\n",
    "    differ_types_pending = [d for d in differ_types if d not in diff_vectors]\n",
    "    with mp.Pool() as pool:\n",
    "        dv_f = functools.partial(differ.get_diff_vector, filepath=segment)\n",
    "        diff_vectors_new = pool.map(dv_f, differ_types_pending)\n",
    "    diff_vectors_new = {\n",
    "        differ_type: vector\n",
    "        for differ_type, vector in zip(differ_types_pending, diff_vectors_new)\n",
    "    }\n",
    "    for differ_type, vector in diff_vectors_new.items():\n",
    "        diff_vector_record = DiffVector(\n",
    "            segment=segment_record,\n",
    "            differencer=differ_type,\n",
    "            vector=vector,\n",
    "        )\n",
    "        diff_vector_record.save()\n",
    "\n",
    "    diff_vectors = {**diff_vectors, **diff_vectors_new}\n",
    "    diff_results = differ.process_video(segment, diff_vectors)\n",
    "    dump_json(diff_results, f'data/diff/{dataset_name}/{segment.parent.name}/{segment.stem}.json', mkdir=True)\n",
    "\n",
    "    # -- evaluation ------------------------------------------------\n",
    "    frame_pairs = evaluator.get_frame_pairs(inference, diff_results)\n",
    "\n",
    "    per_frame_evaluations = {}\n",
    "    for metric in evaluator.keys:\n",
    "        metric_evaluations = FrameEvaluation.objects(segment=segment_record, evaluator=metric)\n",
    "        pairs = [(me.ground_truth, me.comparision) for me in metric_evaluations]\n",
    "        pairs_pending = [p for p in frame_pairs if p not in pairs]\n",
    "        with mp.Pool() as pool:\n",
    "            eval_f = functools.partial(evaluator.evaluate_frame_pair, inference=inference, metric=metric)\n",
    "            metric_evaluations_new = pool.map(eval_f, pairs_pending)\n",
    "        pair_evaluations_new = {\n",
    "            pair: evaluation\n",
    "            for pair, evaluation in zip(pairs_pending, metric_evaluations_new)\n",
    "        }\n",
    "        for pair, evaluation in pair_evaluations_new.items():\n",
    "            frame_evaluation_record = FrameEvaluation(\n",
    "                segment=segment_record,\n",
    "                model=model.name,\n",
    "                evaluator=metric,\n",
    "                ground_truth=pair[0],\n",
    "                comparision=pair[1],\n",
    "                result=evaluation[metric],\n",
    "            )\n",
    "            frame_evaluation_record.save()\n",
    "        for me in metric_evaluations:\n",
    "            if not per_frame_evaluations.get((me.ground_truth, me.comparision), None):\n",
    "                per_frame_evaluations[(me.ground_truth, me.comparision)] = {}\n",
    "            per_frame_evaluations[(me.ground_truth, me.comparision)][metric] = me.result\n",
    "        for pair, evaluation in pair_evaluations_new.items():\n",
    "            if not per_frame_evaluations.get(pair, None):\n",
    "                per_frame_evaluations[pair] = {}\n",
    "            per_frame_evaluations[pair][metric] = evaluation[metric]\n",
    "\n",
    "    evaluations = evaluator.evaluate(inference, diff_results, per_frame_evaluations, segment)\n",
    "    dump_json(evaluations, f'data/evaluation/{dataset_name}/{segment.parent.name}/{segment.stem}.json', mkdir=True)\n",
    "\n",
    "    pbar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
